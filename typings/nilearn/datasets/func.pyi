"""
This type stub file was generated by pyright.
"""

from .._utils import fill_doc

"""Downloading NeuroImaging datasets: \
functional datasets (task + resting-state)."""
_LEGACY_FORMAT_MSG = ...
@fill_doc
def fetch_haxby(data_dir=..., subjects=..., fetch_stimuli=..., url=..., resume=..., verbose=...): # -> Bunch:
    """Download and loads complete haxby dataset.

    See :footcite:`Haxby2001`.

    Parameters
    ----------
    %(data_dir)s
    subjects : list or int, optional
        Either a list of subjects or the number of subjects to load,
        from 1 to 6.
        By default, 2nd subject will be loaded.
        Empty list returns no subject data. Default=(2,).

    fetch_stimuli : boolean, optional
        Indicate if stimuli images must be downloaded.
        They will be presented as a dictionary of categories. Default=False.
    %(url)s
    %(resume)s
    %(verbose)s

    Returns
    -------
    data : sklearn.datasets.base.Bunch
        Dictionary-like object, the interest attributes are :

        - 'anat': string list. Paths to anatomic images.
        - 'func': string list. Paths to nifti file with bold data.
        - 'session_target': string list.
          Paths to text file containing session and target data.
        - 'mask': string. Path to fullbrain mask file.
        - 'mask_vt': string list. Paths to nifti ventral temporal mask file.
        - 'mask_face': string list. Paths to nifti ventral temporal mask file.
        - 'mask_house': string list. Paths to nifti ventral temporal mask file.
        - 'mask_face_little': string list.
          Paths to nifti ventral temporal mask file.
        - 'mask_house_little': string list.
          Paths to nifti ventral temporal mask file.

    References
    ----------
    .. footbibliography::

    Notes
    -----
    PyMVPA provides a tutorial making use of this dataset:
    http://www.pymvpa.org/tutorial.html

    More information about its structure:
    http://dev.pymvpa.org/datadb/haxby2001.html

    See `additional information
    <http://www.sciencemag.org/content/293/5539/2425>`

    Run 8 in subject 5 does not contain any task labels.
    The anatomical image for subject 6 is unavailable.

    """
    ...

def adhd_ids(): # -> list[str]:
    """Return subject ids for the ADHD dataset."""
    ...

@fill_doc
def fetch_adhd(n_subjects=..., data_dir=..., url=..., resume=..., verbose=...): # -> Bunch:
    """Download and load the ADHD resting-state dataset.

    See :footcite:`ADHDdataset`.

    Parameters
    ----------
    n_subjects : int, optional
        The number of subjects to load from maximum of 40 subjects.
        By default, 30 subjects will be loaded. If None is given,
        all 40 subjects will be loaded. Default=30.
    %(data_dir)s
    %(url)s
    %(resume)s
    %(verbose)s

    Returns
    -------
    data : sklearn.datasets.base.Bunch
        Dictionary-like object, the interest attributes are :

         - 'func': Paths to functional resting-state images
         - 'phenotypic': Explanations of preprocessing steps
         - 'confounds': CSV files containing the nuisance variables

    References
    ----------
    .. footbibliography::

    """
    ...

def miyawaki2008_file_mask(): # -> list[str]:
    """Return file listing for the miyawaki 2008 dataset."""
    ...

@fill_doc
def fetch_miyawaki2008(data_dir=..., url=..., resume=..., verbose=...): # -> Bunch:
    """Download and loads Miyawaki et al. 2008 dataset (153MB).

    See :footcite:`Miyawaki2008`.

    Parameters
    ----------
    %(data_dir)s
    %(url)s
    %(resume)s
    %(verbose)s

    Returns
    -------
    data : Bunch
        Dictionary-like object, the interest attributes are :

        - 'func': string list
            Paths to nifti file with bold data
        - 'label': string list
            Paths to text file containing session and target data
        - 'mask': string
            Path to nifti mask file to define target volume in visual
            cortex
        - 'background': string
            Path to nifti file containing a background image usable as a
            background image for miyawaki images.

    References
    ----------
    .. footbibliography::

    Notes
    -----
    This dataset is available on the `brainliner website
    <http://brainliner.jp/data/brainliner-admin/Reconstruct>`_

    See `additional information
    <http://www.cns.atr.jp/dni/en/downloads/
    fmri-data-set-for-visual-image-reconstruction/>`_

    """
    ...

@fill_doc
def fetch_localizer_contrasts(contrasts, n_subjects=..., get_tmaps=..., get_masks=..., get_anats=..., data_dir=..., url=..., resume=..., verbose=..., legacy_format=...): # -> Bunch:
    """Download and load Brainomics/Localizer dataset (94 subjects).

    "The Functional Localizer is a simple and fast acquisition
    procedure based on a 5-minute functional magnetic resonance
    imaging (fMRI) sequence that can be run as easily and as
    systematically as an anatomical scan. This protocol captures the
    cerebral bases of auditory and visual perception, motor actions,
    reading, language comprehension and mental calculation at an
    individual level. Individual functional maps are reliable and
    quite precise. The procedure is described in more detail on the
    Functional Localizer page."
    (see https://osf.io/vhtf6/)

    You may cite :footcite:`Papadopoulos-Orfanos2017`
    when using this dataset.

    Scientific results obtained using this dataset are described
    in :footcite:`Pinel2007`.

    Parameters
    ----------
    contrasts : list of str
        The contrasts to be fetched (for all 94 subjects available).
        Allowed values are::

        - "checkerboard"
        - "horizontal checkerboard"
        - "vertical checkerboard"
        - "horizontal vs vertical checkerboard"
        - "vertical vs horizontal checkerboard"
        - "sentence listening"
        - "sentence reading"
        - "sentence listening and reading"
        - "sentence reading vs checkerboard"
        - "calculation (auditory cue)"
        - "calculation (visual cue)"
        - "calculation (auditory and visual cue)"
        - "calculation (auditory cue) vs sentence listening"
        - "calculation (visual cue) vs sentence reading"
        - "calculation vs sentences"
        - "calculation (auditory cue) and sentence listening"
        - "calculation (visual cue) and sentence reading"
        - "calculation and sentence listening/reading"
        - "calculation (auditory cue) and sentence listening vs "
        - "calculation (visual cue) and sentence reading"
        - "calculation (visual cue) and sentence reading vs checkerboard"
        - "calculation and sentence listening/reading vs button press"
        - "left button press (auditory cue)"
        - "left button press (visual cue)"
        - "left button press"
        - "left vs right button press"
        - "right button press (auditory cue)"
        - "right button press (visual cue)"
        - "right button press"
        - "right vs left button press"
        - "button press (auditory cue) vs sentence listening"
        - "button press (visual cue) vs sentence reading"
        - "button press vs calculation and sentence listening/reading"

        or equivalently on can use the original names::

        - "checkerboard"
        - "horizontal checkerboard"
        - "vertical checkerboard"
        - "horizontal vs vertical checkerboard"
        - "vertical vs horizontal checkerboard"
        - "auditory sentences"
        - "visual sentences"
        - "auditory&visual sentences"
        - "visual sentences vs checkerboard"
        - "auditory calculation"
        - "visual calculation"
        - "auditory&visual calculation"
        - "auditory calculation vs auditory sentences"
        - "visual calculation vs sentences"
        - "auditory&visual calculation vs sentences"
        - "auditory processing"
        - "visual processing"
        - "visual processing vs auditory processing"
        - "auditory processing vs visual processing"
        - "visual processing vs checkerboard"
        - "cognitive processing vs motor"
        - "left auditory click"
        - "left visual click"
        - "left auditory&visual click"
        - "left auditory & visual click vs right auditory&visual click"
        - "right auditory click"
        - "right visual click"
        - "right auditory&visual click"
        - "right auditory & visual click vs left auditory&visual click"
        - "auditory click vs auditory sentences"
        - "visual click vs visual sentences"
        - "auditory&visual motor vs cognitive processing"

    n_subjects : int or list, optional
        The number or list of subjects to load. If None is given,
        all 94 subjects are used.

    get_tmaps : boolean, optional
        Whether t maps should be fetched or not. Default=False.

    get_masks : boolean, optional
        Whether individual masks should be fetched or not.
        Default=False.

    get_anats : boolean, optional
        Whether individual structural images should be fetched or not.
        Default=False.
    %(data_dir)s
    %(url)s
    %(resume)s
    %(verbose)s
    %(legacy_format)s

    Returns
    -------
    data : Bunch
        Dictionary-like object, the interest attributes are :

        - 'cmaps': string list
            Paths to nifti contrast maps
        - 'tmaps' string list (if 'get_tmaps' set to True)
            Paths to nifti t maps
        - 'masks': string list
            Paths to nifti files corresponding to the subjects individual masks
        - 'anats': string
            Path to nifti files corresponding to the subjects structural images

    References
    ----------
    .. footbibliography::

    See Also
    --------
    nilearn.datasets.fetch_localizer_calculation_task
    nilearn.datasets.fetch_localizer_button_task

    """
    ...

@fill_doc
def fetch_localizer_calculation_task(n_subjects=..., data_dir=..., url=..., verbose=..., legacy_format=...): # -> Bunch:
    """Fetch calculation task contrast maps from the localizer.

    Parameters
    ----------
    n_subjects : int, optional
        The number of subjects to load. If None is given,
        all 94 subjects are used. Default=1.
    %(data_dir)s
    %(url)s
    %(verbose)s
    %(legacy_format)s

    Returns
    -------
    data : Bunch
        Dictionary-like object, the interest attributes are :
        'cmaps': string list, giving paths to nifti contrast maps

    Notes
    -----
    This function is only a caller for the fetch_localizer_contrasts in order
    to simplify examples reading and understanding.
    The 'calculation (auditory and visual cue)' contrast is used.

    See Also
    --------
    nilearn.datasets.fetch_localizer_button_task
    nilearn.datasets.fetch_localizer_contrasts

    """
    ...

@fill_doc
def fetch_localizer_button_task(data_dir=..., url=..., verbose=..., legacy_format=...): # -> Bunch:
    """Fetch left vs right button press contrast maps from the localizer.

    Parameters
    ----------
    %(data_dir)s
    %(url)s
    %(verbose)s
    %(legacy_format)s

    Returns
    -------
    data : Bunch
        Dictionary-like object, the interest attributes are :

        - 'cmaps': string list, giving paths to nifti contrast maps
        - 'tmap': string, giving paths to nifti contrast maps
        - 'anat': string, giving paths to normalized anatomical image

    Notes
    -----
    This function is only a caller for the fetch_localizer_contrasts in order
    to simplify examples reading and understanding.
    The 'left vs right button press' contrast is used.

    See Also
    --------
    nilearn.datasets.fetch_localizer_calculation_task
    nilearn.datasets.fetch_localizer_contrasts

    """
    ...

@fill_doc
def fetch_abide_pcp(data_dir=..., n_subjects=..., pipeline=..., band_pass_filtering=..., global_signal_regression=..., derivatives=..., quality_checked=..., url=..., verbose=..., legacy_format=..., **kwargs): # -> Bunch:
    """Fetch ABIDE dataset.

    Fetch the Autism Brain Imaging Data Exchange (ABIDE) dataset wrt criteria
    that can be passed as parameter. Note that this is the preprocessed
    version of ABIDE provided by the preprocess connectome projects (PCP).
    See :footcite:`Nielsen2013`.

    Parameters
    ----------
    %(data_dir)s
    n_subjects : int, optional
        The number of subjects to load. If None is given,
        all available subjects are used (this number depends on the
        preprocessing pipeline used).

    pipeline : string {'cpac', 'css', 'dparsf', 'niak'}, optional
        Possible pipelines are "ccs", "cpac", "dparsf" and "niak".
        Default='cpac'.

    band_pass_filtering : boolean, optional
        Due to controversies in the literature, band pass filtering is
        optional. If true, signal is band filtered between 0.01Hz and 0.1Hz.
        Default=False.

    global_signal_regression : boolean optional
        Indicates if global signal regression should be applied on the
        signals. Default=False.

    derivatives : string list, optional
        Types of downloaded files. Possible values are: alff, degree_binarize,
        degree_weighted, dual_regression, eigenvector_binarize,
        eigenvector_weighted, falff, func_mask, func_mean, func_preproc, lfcd,
        reho, rois_aal, rois_cc200, rois_cc400, rois_dosenbach160, rois_ez,
        rois_ho, rois_tt, and vmhc. Please refer to the PCP site for more
        details. Default=['func_preproc'].

    quality_checked : boolean, optional
        If true (default), restrict the list of the subjects to the one that
        passed quality assessment for all raters. Default=True.
    %(url)s
    %(verbose)s
    %(legacy_format)s
    kwargs : parameter list, optional
        Any extra keyword argument will be used to filter downloaded subjects
        according to the CSV phenotypic file. Some examples of filters are
        indicated below.

    SUB_ID : list of integers in [50001, 50607], optional
        Ids of the subjects to be loaded.

    DX_GROUP : integer in {1, 2}, optional
        1 is autism, 2 is control.

    DSM_IV_TR : integer in [0, 4], optional
        O is control, 1 is autism, 2 is Asperger, 3 is PPD-NOS,
        4 is Asperger or PPD-NOS.

    AGE_AT_SCAN : float in [6.47, 64], optional
        Age of the subject.

    SEX : integer in {1, 2}, optional
        1 is male, 2 is female.

    HANDEDNESS_CATEGORY : string in {'R', 'L', 'Mixed', 'Ambi'}, optional
        R = Right, L = Left, Ambi = Ambidextrous.

    HANDEDNESS_SCORE : integer in [-100, 100], optional
        Positive = Right, Negative = Left, 0 = Ambidextrous.

    Notes
    -----
    Code and description of preprocessing pipelines are provided on the
    `PCP website <http://preprocessed-connectomes-project.github.io/>`.

    References
    ----------
    .. footbibliography::

    """
    ...

@fill_doc
def fetch_mixed_gambles(n_subjects=..., data_dir=..., url=..., resume=..., return_raw_data=..., verbose=...): # -> Bunch:
    """Fetch Jimura "mixed gambles" dataset.

    See :footcite:`Jimura2012`.

    Parameters
    ----------
    n_subjects : :obj:`int`, optional
        The number of subjects to load. If ``None`` is given, all the
        subjects are used. Default=1.
    %(data_dir)s
    %(url)s
    %(resume)s
    %(verbose)s
    return_raw_data : :obj:`bool`, optional
        If ``False``, then the data will transformed into an ``(X, y)``
        pair, suitable for machine learning routines. ``X`` is a list
        of ``n_subjects * 48`` :class:`~nibabel.nifti1.Nifti1Image`
        objects (where 48 is the number of trials), and ``y`` is an
        array of shape ``(n_subjects * 48,)``.
        Default=False.

    Returns
    -------
    data : :class:`~sklearn.utils.Bunch`
        Dictionary-like object, the attributes of interest are:

        - 'zmaps': :obj:`list` of :obj:`str`
          Paths to realigned gain betamaps (one nifti per subject).
        - 'gain': :obj:`list` of :class:`~nibabel.nifti1.Nifti1Image` \
        or ``None``
          If ``make_Xy`` is ``True``, this is a list of
          ``n_subjects * 48`` :class:`~nibabel.nifti1.Nifti1Image`
          objects, else it is ``None``.
        - 'y': :class:`~numpy.ndarray` of shape ``(n_subjects * 48,)`` \
        or ``None``
          If ``make_Xy`` is ``True``, then this is a
          :class:`~numpy.ndarray` of shape ``(n_subjects * 48,)``,
          else it is ``None``.

    References
    ----------
    .. footbibliography::

    """
    ...

@fill_doc
def fetch_megatrawls_netmats(dimensionality=..., timeseries=..., matrices=..., data_dir=..., resume=..., verbose=...): # -> Bunch:
    """Download and return Network Matrices data \
    from MegaTrawls release in HCP.

    This data can be used to predict relationships between imaging data and
    non-imaging behavioural measures such as age, sex, education, etc.
    The network matrices are estimated from functional connectivity
    datasets of 461 subjects. Full technical details in references.

    More information available in :footcite:`Smith2015b`,
    :footcite:`Smith2015a`, :footcite:`Filippini2009`,
    :footcite:`Smith2014`, and :footcite:`Reilly2009`.

    Parameters
    ----------
    dimensionality : int, optional
        Valid inputs are 25, 50, 100, 200, 300. By default, network matrices
        estimated using Group ICA brain parcellations
        of 100 components/dimensions will be returned. Default=100.

    timeseries : str, optional
        Valid inputs are 'multiple_spatial_regression' or 'eigen_regression'.
        By default 'eigen_regression', matrices estimated using first principal
        eigen component timeseries signals extracted from each subject data
        parcellations will be returned.
        Otherwise, 'multiple_spatial_regression'
        matrices estimated using spatial regressor based timeseries signals
        extracted from each subject data parcellations will be returned.
        Default='eigen_regression'.

    matrices : str, optional
        Valid inputs are 'full_correlation' or 'partial_correlation'.
        By default, partial correlation matrices will be returned
        otherwise if selected full correlation matrices will be returned.
        Default='partial_correlation'.
    %(data_dir)s
    %(resume)s
    %(verbose)s

    Returns
    -------
    data : Bunch
        Dictionary-like object, the attributes are :

        - 'dimensions': int, consists of given input in dimensions.

        - 'timeseries': str, consists of given input in timeseries method.

        - 'matrices': str, consists of given type of specific matrices.

        - 'correlation_matrices': ndarray, consists of correlation matrices
          based on given type of matrices. Array size will depend on given
          dimensions (n, n).

        - 'description': data description

    References
    ----------
    .. footbibliography::

    Notes
    -----
    See description for terms & conditions on data usage.

    """
    ...

def nki_ids(): # -> list[str]:
    """Return the subject ids of the NKI dataset."""
    ...

@fill_doc
def fetch_surf_nki_enhanced(n_subjects=..., data_dir=..., url=..., resume=..., verbose=...): # -> Bunch:
    """Download and load the NKI enhanced resting-state dataset, \
    preprocessed and projected to the fsaverage5 space surface.

    See :footcite:`Nooner2012`.

    Direct download link :footcite:`NKIdataset`.

    .. versionadded:: 0.3

    Parameters
    ----------
    n_subjects : int, optional
        The number of subjects to load from maximum of 102 subjects.
        By default, 10 subjects will be loaded. If None is given,
        all 102 subjects will be loaded. Default=10.
    %(data_dir)s
    %(url)s
    %(resume)s
    %(verbose)s

    Returns
    -------
    data : sklearn.datasets.base.Bunch
        Dictionary-like object, the interest attributes are :

        - 'func_left': Paths to Gifti files containing resting state
                        time series left hemisphere
        - 'func_right': Paths to Gifti files containing resting state
                         time series right hemisphere
        - 'phenotypic': array containing tuple with subject ID, age,
                         dominant hand and sex for each subject.
        - 'description': data description of the release and references.

    References
    ----------
    .. footbibliography::

    """
    ...

@fill_doc
def fetch_development_fmri(n_subjects=..., reduce_confounds=..., data_dir=..., resume=..., verbose=..., age_group=...): # -> Bunch:
    """Fetch movie watching based brain development dataset (fMRI).

    The data is downsampled to 4mm resolution for convenience
    with a repetition time (TR) of 2 secs.
    The origin of the data is coming from OpenNeuro. See Notes below.

    Please cite :footcite:`Richardson2018`
    if you are using this dataset.

    .. versionadded:: 0.5.2

    Parameters
    ----------
    n_subjects : int, optional
        The number of subjects to load. If None, all the subjects are
        loaded. Total 155 subjects.

    reduce_confounds : bool, optional
        If True, the returned confounds only include 6 motion parameters,
        mean framewise displacement, signal from white matter, csf, and
        6 anatomical compcor parameters. This selection only serves the
        purpose of having realistic examples. Depending on your research
        question, other confounds might be more appropriate.
        If False, returns all :term:`fMRIPrep` confounds.
        Default=True.
    %(data_dir)s
    %(resume)s
    %(verbose)s
    age_group : str, optional
        Default='both'. Which age group to fetch

        - 'adults' = fetch adults only (n=33, ages 18-39)
        - 'child' = fetch children only (n=122, ages 3-12)
        - 'both' = fetch full sample (n=155)

    Returns
    -------
    data : Bunch
        Dictionary-like object, the interest attributes are :

        - 'func': list of str (Nifti files)
            Paths to downsampled functional MRI data (4D) for each subject.

        - 'confounds': list of str (tsv files)
            Paths to confounds related to each subject.

        - 'phenotypic': numpy.ndarray
            Contains each subject age, age group, child or adult, gender,
            handedness.

    Notes
    -----
    The original data is downloaded from OpenNeuro
    https://openneuro.org/datasets/ds000228/versions/1.0.0

    This fetcher downloads downsampled data that are available on Open
    Science Framework (OSF). Located here: https://osf.io/5hju4/files/

    Preprocessing details: https://osf.io/wjtyq/

    Note that if n_subjects > 2, and age_group is 'both',
    fetcher will return a ratio of children and adults representative
    of the total sample.

    References
    ----------
    .. footbibliography::

    """
    ...

@fill_doc
def fetch_language_localizer_demo_dataset(data_dir=..., verbose=...): # -> tuple[Unknown, list[Unknown]]:
    """Download language localizer demo dataset.

    Parameters
    ----------
    %(data_dir)s
    %(verbose)s

    Returns
    -------
    data_dir : string
        Path to downloaded dataset.

    downloaded_files : list of string
        Absolute paths of downloaded files on disk

    """
    ...

@fill_doc
def fetch_bids_langloc_dataset(data_dir=..., verbose=...): # -> tuple[str, list[str]]:
    """Download language localizer example :term:`bids<BIDS>` dataset.

    Parameters
    ----------
    %(data_dir)s
    %(verbose)s

    Returns
    -------
    data_dir : string
        Path to downloaded dataset.

    downloaded_files : list of string
        Absolute paths of downloaded files on disk.

    """
    ...

@fill_doc
def fetch_openneuro_dataset_index(data_dir=..., dataset_version=..., verbose=...): # -> tuple[Unknown, Any]:
    """Download a file with OpenNeuro :term:`BIDS` dataset index.

    .. deprecated:: 0.9.2
        `fetch_openneuro_dataset_index` will be removed in 0.11.

    Downloading the index allows to explore the dataset directories
    to select specific files to download. The index is a sorted list of urls.

    Parameters
    ----------
    %(data_dir)s
    dataset_version : :obj:`str`, optional
        Dataset version name. Assumes it is of the form [name]_[version].
        Default='ds000030_R1.0.4'.

        .. warning:: Any value other than the default will be ignored.

    %(verbose)s'

    Returns
    -------
    urls_path : :obj:`str`
        Path to downloaded dataset index.
    urls : :obj:`list` of :obj:`str`
        Sorted list of dataset directories.
    """
    ...

@fill_doc
def fetch_ds000030_urls(data_dir=..., verbose=...): # -> tuple[Unknown, Any]:
    """Fetch URLs for files from the ds000030 :term:`BIDS` dataset.

    .. versionadded:: 0.9.2

    This dataset is version 1.0.4 of the "UCLA Consortium for
    Neuropsychiatric Phenomics LA5c" dataset
    :footcite:p:`Poldrack2016`.

    Downloading the index allows users to explore the dataset directories
    to select specific files to download.
    The index is a sorted list of urls.

    Parameters
    ----------
    %(data_dir)s
    %(verbose)s

    Returns
    -------
    urls_path : :obj:`str`
        Path to downloaded dataset index.

    urls : :obj:`list` of :obj:`str`
        Sorted list of dataset directories.

    References
    ----------
    .. footbibliography::
    """
    ...

def select_from_index(urls, inclusion_filters=..., exclusion_filters=..., n_subjects=...): # -> list[Unknown]:
    """Select subset of urls with given filters.

    Parameters
    ----------
    urls : list of str
        List of dataset urls obtained from index download.

    inclusion_filters : list of str, optional
        List of unix shell-style wildcard strings
        that will be used to filter the url list.
        If a filter matches the url it is retained for download.
        Multiple filters work on top of each other.
        Like an "and" logical operator, creating a more restrictive query.
        Inclusion and exclusion filters apply together.
        For example the filter '*task-rest*'' would keep only urls
        that contain the 'task-rest' string.

    exclusion_filters : list of str, optional
        List of unix shell-style wildcard strings
        that will be used to filter the url list.
        If a filter matches the url it is discarded for download.
        Multiple filters work on top of each other.
        Like an "and" logical operator, creating a more restrictive query.
        Inclusion and exclusion filters apply together.
        For example the filter '*task-rest*' would discard all urls
        that contain the 'task-rest' string.

    n_subjects : int, optional
        Number of subjects to download from the dataset. All by default.

    Returns
    -------
    urls : list of string
        Sorted list of filtered dataset directories.

    """
    ...

def patch_openneuro_dataset(file_list): # -> None:
    """Add symlinks for files not named according to :term:`BIDS` conventions.

    .. warning::
        This function uses a series of hardcoded patterns to generate the
        corrected filenames.
        These patterns are not comprehensive and this function is not
        guaranteed to produce BIDS-compliant files.

    Parameters
    ----------
    file_list : :obj:`list` of :obj:`str`
        A list of filenames to update.
    """
    ...

@fill_doc
def fetch_openneuro_dataset(urls=..., data_dir=..., dataset_version=..., verbose=...): # -> tuple[Unknown, list[Unknown]]:
    """Download OpenNeuro :term:`BIDS` dataset.

    This function specifically downloads files from a series of URLs.
    Unless you use :func:`fetch_ds000030_urls` or the default parameters,
    it is up to the user to ensure that the URLs are correct,
    and that they are associated with an OpenNeuro dataset.

    Parameters
    ----------
    urls : list of string, optional
        List of URLs to dataset files to download.
        If not specified, all files from the default dataset
        (``ds000030_R1.0.4``) will be downloaded.
    %(data_dir)s
    dataset_version : string, optional
        Dataset version name. Assumes it is of the form [name]_[version].
        Default is ``ds000030_R1.0.4``.
    %(verbose)s

    Returns
    -------
    data_dir : string
        Path to downloaded dataset.

    downloaded_files : list of string
        Absolute paths of downloaded files on disk.

    Notes
    -----
    The default dataset downloaded by this function is the
    "UCLA Consortium for Neuropsychiatric Phenomics LA5c" dataset
    :footcite:p:`Poldrack2016`.

    This copy includes filenames that are not compliant with the current
    version of :term:`BIDS`, so this function also calls
    :func:`patch_openneuro_dataset` to generate BIDS-compliant symlinks.

    See Also
    --------
    :func:`fetch_ds000030_urls`
    :func:`patch_openneuro_dataset`

    References
    ----------
    .. footbibliography::
    """
    ...

@fill_doc
def fetch_localizer_first_level(data_dir=..., verbose=...): # -> Bunch:
    """Download a first-level localizer fMRI dataset.

    Parameters
    ----------
    %(data_dir)s
    %(verbose)s

    Returns
    -------
    data : sklearn.datasets.base.Bunch
        Dictionary-like object, with the keys:
        epi_img: the input 4D image
        events: a csv file describing the paardigm

    """
    ...

@fill_doc
def fetch_spm_auditory(data_dir=..., data_name=..., subject_id=..., verbose=...): # -> Bunch | None:
    """Fetch SPM auditory single-subject data.

    See :footcite:`spm_auditory`.

    Parameters
    ----------
    %(data_dir)s
    data_name : string, optional
        Name of the dataset. Default='spm_auditory'.

    subject_id : string, optional
        Indicates which subject to retrieve.
        Default='sub001'.
    %(verbose)s

    Returns
    -------
    data : sklearn.datasets.base.Bunch
        Dictionary-like object, the interest attributes are:
        - 'func': string list. Paths to functional images
        - 'anat': string list. Path to anat image

    References
    ----------
    .. footbibliography::

    """
    ...

@fill_doc
def fetch_spm_multimodal_fmri(data_dir=..., data_name=..., subject_id=..., verbose=...): # -> Bunch | None:
    """Fetcher for Multi-modal Face Dataset.

    See :footcite:`spm_multiface`.

    Parameters
    ----------
    %(data_dir)s
    data_name : string, optional
        Name of the dataset. Default='spm_multimodal_fmri'.

    subject_id : string, optional
        Indicates which subject to retrieve. Default='sub001'.
    %(verbose)s

    Returns
    -------
    data : sklearn.datasets.base.Bunch
        Dictionary-like object, the interest attributes are:
        - 'func1': string list. Paths to functional images for session 1
        - 'func2': string list. Paths to functional images for session 2
        - 'trials_ses1': string list. Path to onsets file for session 1
        - 'trials_ses2': string list. Path to onsets file for session 2
        - 'anat': string. Path to anat file

    References
    ----------
    .. footbibliography::

    """
    ...

@fill_doc
def fetch_fiac_first_level(data_dir=..., verbose=...): # -> Bunch | None:
    """Download a first-level fiac fMRI dataset (2 sessions).

    Parameters
    ----------
    %(data_dir)s
    %(verbose)s

    """
    ...

