"""
This type stub file was generated by pyright.
"""

from .._utils import fill_doc
from ..decomposition._multi_pca import _MultiPCA

"""Parcellation tools such as KMeans or Ward for fMRI images."""
@fill_doc
class Parcellations(_MultiPCA):
    """Learn :term:`parcellations<parcellation>` \
    on :term:`fMRI` images.

    Five different types of clustering methods can be used:
    kmeans, ward, complete, average and rena.
    kmeans will call MiniBatchKMeans whereas
    ward, complete, average are used within in Agglomerative Clustering and
    rena will call ReNA.
    kmeans, ward, complete, average are leveraged from scikit-learn.
    rena is built into nilearn.

    .. versionadded:: 0.4.1

    Parameters
    ----------
    method: :obj:`str`, {'kmeans', 'ward', 'complete', 'average', 'rena',
        'hierarchical_kmeans'}
        A method to choose between for brain parcellations.
        For a small number of parcels, kmeans is usually advisable.
        For a large number of parcellations (several hundreds, or thousands),
        ward and rena are the best options. Ward will give higher quality
        parcels, but with increased computation time. ReNA is most useful as a
        fast data-reduction step, typically dividing the signal size by ten.

    n_parcels : :obj:`int`, default=50
        Number of parcels to divide the data into.

    %(random_state)s
        Default=0.

    mask : Niimg-like object or :class:`nilearn.maskers.NiftiMasker`,\
 :class:`nilearn.maskers.MultiNiftiMasker`, optional
        Mask/Masker used for masking the data.
        If mask image if provided, it will be used in the MultiNiftiMasker.
        If an instance of MultiNiftiMasker is provided, then this instance
        parameters will be used in masking the data by overriding the default
        masker parameters.
        If None, mask will be automatically computed by a MultiNiftiMasker
        with default parameters.
    %(smoothing_fwhm)s
        Default=4.0.
    %(standardize_false)s
    %(detrend)s

        .. note::
            This parameter is passed to :func:`nilearn.signal.clean`.
            Please see the related documentation for details.

        Default=False.
    %(low_pass)s

        .. note::
            This parameter is passed to :func:`nilearn.signal.clean`.
            Please see the related documentation for details.

    %(high_pass)s

        .. note::
            This parameter is passed to :func:`nilearn.signal.clean`.
            Please see the related documentation for details.

    %(t_r)s

        .. note::
            This parameter is passed to :func:`nilearn.signal.clean`.
            Please see the related documentation for details.

    %(target_affine)s

        .. note::
            This parameter is passed to :func:`nilearn.image.resample_img`.
            Please see the related documentation for details.

        .. note::
            The given affine will be considered as same for all
            given list of images.

    %(target_shape)s

        .. note::
            This parameter is passed to :func:`nilearn.image.resample_img`.
            Please see the related documentation for details.

    %(mask_strategy)s

        .. note::
             Depending on this value, the mask will be computed from
             :func:`nilearn.masking.compute_background_mask`,
             :func:`nilearn.masking.compute_epi_mask`, or
             :func:`nilearn.masking.compute_brain_mask`.

        Default='epi'.

    mask_args : :obj:`dict`, optional
        If mask is None, these are additional parameters passed to
        masking.compute_background_mask or masking.compute_epi_mask
        to fine-tune mask computation. Please see the related documentation
        for details.

    scaling : :obj:`bool`, optional
        Used only when the method selected is 'rena'. If scaling is True, each
        cluster is scaled by the square root of its size, preserving the
        l2-norm of the image. Default=False.

    n_iter : :obj:`int`, optional
        Used only when the method selected is 'rena'. Number of iterations of
        the recursive neighbor agglomeration. Default=10.
    %(memory)s
    %(memory_level)s
    %(n_jobs)s
    %(verbose0)s

    Attributes
    ----------
    `labels_img_` : :class:`nibabel.nifti1.Nifti1Image`
        Labels image to each parcellation learned on fmri images.

    `masker_` : :class:`nilearn.maskers.NiftiMasker` or\
 :class:`nilearn.maskers.MultiNiftiMasker`
        The masker used to mask the data.

    `connectivity_` : :class:`numpy.ndarray`
        Voxel-to-voxel connectivity matrix computed from a mask.
        Note that this attribute is only seen if selected methods are
        Agglomerative Clustering type, 'ward', 'complete', 'average'.

    Notes
    -----
    * Transforming list of Nifti images to data matrix takes few steps.
      Reducing the data dimensionality using randomized SVD, build brain
      parcellations using KMeans or various Agglomerative methods.

    * This object uses spatially-constrained AgglomerativeClustering for
      method='ward' or 'complete' or 'average' and spatially-constrained
      ReNA clustering for method='rena'. Spatial connectivity matrix
      (voxel-to-voxel) is built-in object which means no need of explicitly
      giving the matrix.

    """
    VALID_METHODS = ...
    def __init__(self, method, n_parcels=..., random_state=..., mask=..., smoothing_fwhm=..., standardize=..., detrend=..., low_pass=..., high_pass=..., t_r=..., target_affine=..., target_shape=..., mask_strategy=..., mask_args=..., scaling=..., n_iter=..., memory=..., memory_level=..., n_jobs=..., verbose=...) -> None:
        ...
    
    @fill_doc
    def transform(self, imgs, confounds=...): # -> Generator[Unknown | None, Any, None] | list[Unknown | None] | Generator[Unknown | None, Unknown, None] | None:
        """Extract signals from :term:`parcellations<parcellation>` learned \
        on :term:`fMRI` images.

        Parameters
        ----------
        %(imgs)s
            Images to process.

        confounds : :obj:`list` of CSV files, arrays-like,\
 or :class:`pandas.DataFrame`, optional
            Each file or numpy array in a list should have shape
            (number of scans, number of confounds)
            Must be of same length as imgs.

            .. note::
                This parameter is passed to :func:`nilearn.signal.clean`.
                Please see the related documentation for details.

        Returns
        -------
        region_signals : :obj:`list` of or 2D :class:`numpy.ndarray`
            Signals extracted for each label for each image.
            Example, for single image shape will be
            (number of scans, number of labels)

        """
        ...
    
    @fill_doc
    def fit_transform(self, imgs, confounds=...): # -> Generator[Unknown | None, Any, None] | list[Unknown | None] | Generator[Unknown | None, Unknown, None] | None:
        """Fit the images to :term:`parcellations<parcellation>` and \
        then transform them.

        Parameters
        ----------
        %(imgs)s
            Images for process for fit as well for transform to signals.

        confounds : :obj:`list` of CSV files, arrays-like or\
 :class:`pandas.DataFrame`, optional
            Each file or numpy array in a list should have shape
            (number of scans, number of confounds).
            Given confounds should have same length as images if
            given as a list.

            .. note::
                This parameter is passed to :func:`nilearn.signal.clean`.
                Please see the related documentation for details.

            .. note::
                Confounds will be used for cleaning signals before
                learning parcellations.

        Returns
        -------
        region_signals : :obj:`list` of or 2D :class:`numpy.ndarray`
            Signals extracted for each label for each image.
            Example, for single image shape will be
            (number of scans, number of labels)

        """
        ...
    
    @fill_doc
    def inverse_transform(self, signals): # -> Generator[Unknown | None, Any, None] | list[Unknown | None] | Generator[Unknown | None, Unknown, None] | None:
        """Transform signals extracted \
        from :term:`parcellations<parcellation>` back to brain images.

        Uses `labels_img_` (parcellations) built at fit() level.

        Parameters
        ----------
        signals : :obj:`list` of 2D :class:`numpy.ndarray`
            Each 2D array with shape (number of scans, number of regions).

        Returns
        -------
        %(imgs)s
            Brain image(s).

        """
        ...
    


