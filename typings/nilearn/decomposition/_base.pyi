"""
This type stub file was generated by pyright.
"""

from sklearn.base import BaseEstimator, TransformerMixin
from .._utils import fill_doc
from .._utils.cache_mixin import CacheMixin

"""Base class for decomposition estimators.

Utilities for masking and dimension reduction of group data
"""
@fill_doc
class _BaseDecomposition(BaseEstimator, CacheMixin, TransformerMixin):
    """Base class for matrix factorization based decomposition estimators.

    Handles mask logic, provides transform and inverse_transform methods

     .. versionadded:: 0.2

    Parameters
    ----------
    n_components : int, optional
        Number of components to extract, for each 4D-Niimage
        Default=20.

    random_state : int or RandomState, optional
        Pseudo number generator state used for random sampling.

    mask : Niimg-like object or MultiNiftiMasker instance, optional
        Mask to be used on data. If an instance of masker is passed,
        then its mask will be used. If no mask is given, it will be computed
        automatically by a MultiNiftiMasker with default parameters.
    %(smoothing_fwhm)s
    standardize : boolean, optional
        If standardize is True, the time-series are centered and normed:
        their mean is put to 0 and their variance to 1 in the time dimension.
        Default=True.

    standardize_confounds : boolean, optional
        If standardize_confounds is True, the confounds are z-scored:
        their mean is put to 0 and their variance to 1 in the time dimension.
        Default=True.

    detrend : boolean, optional
        This parameter is passed to signal.clean. Please see the related
        documentation for details. Default=True.

    low_pass : None or float, optional
        This parameter is passed to signal.clean. Please see the related
        documentation for details

    high_pass : None or float, optional
        This parameter is passed to signal.clean. Please see the related
        documentation for details

    t_r : float, optional
        This parameter is passed to signal.clean. Please see the related
        documentation for details

    target_affine : 3x3 or 4x4 matrix, optional
        This parameter is passed to image.resample_img. Please see the
        related documentation for details.

    target_shape : 3-tuple of integers, optional
        This parameter is passed to image.resample_img. Please see the
        related documentation for details.

    %(mask_strategy)s

        .. note::
             Depending on this value, the mask will be computed from
             :func:`nilearn.masking.compute_background_mask`,
             :func:`nilearn.masking.compute_epi_mask`, or
             :func:`nilearn.masking.compute_brain_mask`.

        Default='epi'.

    mask_args : dict, optional
        If mask is None, these are additional parameters passed to
        masking.compute_background_mask or masking.compute_epi_mask
        to fine-tune mask computation. Please see the related documentation
        for details.

    memory : instance of joblib.Memory or str, optional
        Used to cache the masking process.
        By default, no caching is done. If a string is given, it is the
        path to the caching directory.

    memory_level : integer, optional
        Rough estimator of the amount of memory used by caching. Higher value
        means more memory for caching. Default=0.

    n_jobs : integer, optional
        The number of CPUs to use to do the computation. -1 means
        'all CPUs', -2 'all CPUs but one', and so on. Default=1.

    verbose : integer, optional
        Indicate the level of verbosity. By default, nothing is printed.
        Default=0.

    Attributes
    ----------
    `mask_img_` : Niimg-like object
        See :ref:`extracting_data`.
        The mask of the data. If no mask was given at masker creation, contains
        the automatically computed mask.

    """
    def __init__(self, n_components=..., random_state=..., mask=..., smoothing_fwhm=..., standardize=..., standardize_confounds=..., detrend=..., low_pass=..., high_pass=..., t_r=..., target_affine=..., target_shape=..., mask_strategy=..., mask_args=..., memory=..., memory_level=..., n_jobs=..., verbose=...) -> None:
        ...
    
    def fit(self, imgs, y=..., confounds=...): # -> Self@_BaseDecomposition:
        """Compute the mask and the components across subjects.

        Parameters
        ----------
        imgs : list of Niimg-like objects
            See :ref:`extracting_data`.
            Data on which the mask is calculated. If this is a list,
            the affine is considered the same for all.

        confounds : list of CSV file paths, numpy.ndarrays
            or pandas DataFrames, optional.
            This parameter is passed to nilearn.signal.clean.
            Please see the related documentation for details.
            Should match with the list of imgs given.

        Returns
        -------
        self : object
            Returns the instance itself. Contains attributes listed
            at the object level.

        """
        ...
    
    def transform(self, imgs, confounds=...): # -> list[Unknown]:
        """Project the data into a reduced representation.

        Parameters
        ----------
        imgs : iterable of Niimg-like objects
            See :ref:`extracting_data`.
            Data to be projected

        confounds : CSV file path or numpy.ndarray
            or pandas DataFrame, optional
            This parameter is passed to nilearn.signal.clean. Please see the
            related documentation for details

        Returns
        -------
        loadings : list of 2D ndarray,
            For each subject, each sample, loadings for each decomposition
            components
            shape: number of subjects * (number of scans, number of regions)

        """
        ...
    
    def inverse_transform(self, loadings): # -> list[list[Unknown] | Nifti1Image | FileBasedImage | Unknown]:
        """Use provided loadings to compute corresponding linear component \
        combination in whole-brain voxel space.

        Parameters
        ----------
        loadings : list of numpy array (n_samples x n_components)
            Component signals to transform back into voxel signals

        Returns
        -------
        reconstructed_imgs : list of nibabel.Nifti1Image
            For each loading, reconstructed Nifti1Image

        """
        ...
    
    def score(self, imgs, confounds=..., per_component=...): # -> Any | None:
        """Score function based on explained variance on imgs.

        Should only be used by DecompositionEstimator derived classes

        Parameters
        ----------
        imgs : iterable of Niimg-like objects
            See :ref:`extracting_data`.
            Data to be scored

        confounds : CSV file path or numpy.ndarray
            or pandas DataFrame, optional
            This parameter is passed to nilearn.signal.clean. Please see the
            related documentation for details

        per_component : bool, optional
            Specify whether the explained variance ratio is desired for each
            map or for the global set of components. Default=False.

        Returns
        -------
        score : float
            Holds the score for each subjects. Score is two dimensional
            if per_component is True. First dimension
            is squeezed if the number of subjects is one

        """
        ...
    


