"""
This type stub file was generated by pyright.
"""

from .._utils import fill_doc
from .._utils.helpers import rename_parameters

"""
Preprocessing functions for images.

See also nilearn.signal.
"""
def get_data(img): # -> ndarray[Unknown, Unknown] | NDArray[Any]:
    """Get the image data as a :class:`numpy.ndarray`.

    Parameters
    ----------
    img : Niimg-like object or iterable of Niimg-like objects
        See :ref:`extracting_data`.

    Returns
    -------
    :class:`numpy.ndarray`
        3D or 4D numpy array depending on the shape of `img`. This function
        preserves the type of the image data.
        If `img` is an in-memory Nifti image
        it returns the image data array itself -- not a copy.

    """
    ...

def high_variance_confounds(imgs, n_confounds=..., percentile=..., detrend=..., mask_img=...):
    """Return confounds extracted from input signals with highest variance.

    Parameters
    ----------
    imgs : Niimg-like object
        4D image.
        See :ref:`extracting_data`.

    mask_img : Niimg-like object
        If not provided, all voxels are used.
        If provided, confounds are extracted from voxels inside the mask.
        See :ref:`extracting_data`.

    n_confounds : :obj:`int`, optional
        Number of confounds to return. Default=5.

    percentile : :obj:`float`, optional
        Highest-variance signals percentile to keep before computing the
        singular value decomposition, 0. <= `percentile` <= 100.
        `mask_img.sum() * percentile / 100` must be greater than `n_confounds`.
        Default=2.

    detrend : :obj:`bool`, optional
        If True, detrend signals before processing. Default=True.

    Returns
    -------
    :class:`numpy.ndarray`
        Highest variance confounds. Shape: *(number_of_scans, n_confounds)*.

    Notes
    -----
    This method is related to what has been published in the literature
    as 'CompCor' (Behzadi NeuroImage 2007).

    The implemented algorithm does the following:

    - Computes the sum of squares for each signal (no mean removal).
    - Keeps a given percentile of signals with highest variance (percentile).
    - Computes an SVD of the extracted signals.
    - Returns a given number (n_confounds) of signals from the SVD with
      highest singular values.

    See Also
    --------
    nilearn.signal.high_variance_confounds

    """
    ...

@fill_doc
def smooth_img(imgs, fwhm): # -> list[Unknown]:
    """Smooth images by applying a Gaussian filter.

    Apply a Gaussian filter along the three first dimensions of `arr`.
    In all cases, non-finite values in input image are replaced by zeros.

    Parameters
    ----------
    imgs : Niimg-like object or iterable of Niimg-like objects
        Image(s) to smooth (see :ref:`extracting_data`
        for a detailed description of the valid input types).
    %(fwhm)s

    Returns
    -------
    :class:`nibabel.nifti1.Nifti1Image` or list of
        Filtered input image. If `imgs` is an iterable,
        then `filtered_img` is a list.

    """
    ...

def crop_img(img, rtol=..., copy=..., pad=..., return_offset=...): # -> tuple[Nifti1Image | FileBasedImage | Unknown, tuple[slice, ...]] | Nifti1Image | FileBasedImage:
    """Crops an image as much as possible.

    Will crop `img`, removing as many zero entries as possible without
    touching non-zero entries. Will leave one voxel of zero padding
    around the obtained non-zero area in order to avoid sampling issues
    later on.

    Parameters
    ----------
    img : Niimg-like object
        Image to be cropped (see :ref:`extracting_data` for a detailed
        description of the valid input types).

    rtol : :obj:`float`, optional
        relative tolerance (with respect to maximal absolute value of the
        image), under which values are considered negligeable and thus
        croppable. Default=1e-8.

    copy : :obj:`bool`, optional
        Specifies whether cropped data is copied or not. Default=True.

    pad : :obj:`bool`, optional
        Toggles adding 1-voxel of 0s around the border. Default=True.

    return_offset : :obj:`bool`, optional
        Specifies whether to return a tuple of the removed padding.
        Default=False.

    Returns
    -------
    Niimg-like object or :obj:`tuple`
        Cropped version of the input image and, if `return_offset=True`,
        a tuple of tuples representing the number of voxels
        removed (before, after) the cropped volumes, i.e.:
        *[(x1_pre, x1_post), (x2_pre, x2_post), ..., (xN_pre, xN_post)]*

    """
    ...

def mean_img(imgs, target_affine=..., target_shape=..., verbose=..., n_jobs=...): # -> Nifti1Image | FileBasedImage:
    """Compute the mean of the images over time or the 4th dimension.

    Note that if list of 4D images are given, the mean of each 4D image is
    computed separately, and the resulting mean is computed after.

    Parameters
    ----------
    imgs : Niimg-like object or iterable of Niimg-like objects
        Images to be averaged over time (see :ref:`extracting_data`
        for a detailed description of the valid input types).

    target_affine : :class:`numpy.ndarray`, optional
        If specified, the image is resampled corresponding to this new affine.
        target_affine can be a 3x3 or a 4x4 matrix.

    target_shape : :obj:`tuple` or :obj:`list`, optional
        If specified, the image will be resized to match this new shape.
        len(target_shape) must be equal to 3.
        A target_affine has to be specified jointly with target_shape.

    verbose : :obj:`int`, optional
        Controls the amount of verbosity: higher numbers give more messages
        (0 means no messages). Default=0.

    n_jobs : :obj:`int`, optional
        The number of CPUs to use to do the computation (-1 means
        'all CPUs'). Default=1.

    Returns
    -------
    :class:`~nibabel.nifti1.Nifti1Image`
        Mean image.

    See Also
    --------
    nilearn.image.math_img : For more general operations on images.

    """
    ...

def swap_img_hemispheres(img): # -> Nifti1Image | FileBasedImage:
    """Perform swapping of hemispheres in the indicated NIfTI image.

       Use case: synchronizing ROIs across hemispheres.

    Parameters
    ----------
    img : Niimg-like object
        Images to swap (see :ref:`extracting_data` for a detailed description
        of the valid input types).

    Returns
    -------
    :class:`~nibabel.nifti1.Nifti1Image`
        Hemispherically swapped image.

    Notes
    -----
    Assumes that the image is sagitally aligned.

    Should be used with caution (confusion might be caused with
    radio/neuro conventions)

    Note that this does not require a change of the affine matrix.

    """
    ...

def index_img(imgs, index): # -> Nifti1Image | FileBasedImage:
    """Indexes into a 4D Niimg-like object in the fourth dimension.

    Common use cases include extracting a 3D image out of `img` or
    creating a 4D image whose data is a subset of `img` data.

    Parameters
    ----------
    imgs : 4D Niimg-like object
        See :ref:`extracting_data`.

    index : Any type compatible with numpy array indexing
        Used for indexing the 4D data array in the fourth dimension.

    Returns
    -------
    :class:`~nibabel.nifti1.Nifti1Image`
        Indexed image.

    See Also
    --------
    nilearn.image.concat_imgs
    nilearn.image.iter_img

    Examples
    --------
    First we concatenate two MNI152 images to create a 4D-image::

     >>> from nilearn import datasets
     >>> from nilearn.image import concat_imgs, index_img
     >>> joint_mni_image = concat_imgs([datasets.load_mni152_template(),
     ...                                datasets.load_mni152_template()])
     >>> print(joint_mni_image.shape)
     (197, 233, 189, 2)

    We can now select one slice from the last dimension of this 4D-image::

     >>> single_mni_image = index_img(joint_mni_image, 1)
     >>> print(single_mni_image.shape)
     (197, 233, 189)

    We can also select multiple frames using the `slice` constructor::

     >>> five_mni_images = concat_imgs([datasets.load_mni152_template()] * 5)
     >>> print(five_mni_images.shape)
     (197, 233, 189, 5)

     >>> first_three_images = index_img(five_mni_images,
     ...                                slice(0, 3))
     >>> print(first_three_images.shape)
     (197, 233, 189, 3)

    """
    ...

def iter_img(imgs): # -> Nifti1Image | FileBasedImage | Generator[Nifti1Image | FileBasedImage | Unknown, None, None]:
    """Iterate over a 4D Niimg-like object in the fourth dimension.

    Parameters
    ----------
    imgs : 4D Niimg-like object
        See :ref:`extracting_data`.

    Returns
    -------
    Iterator of 3D :class:`~nibabel.nifti1.Nifti1Image`

    See Also
    --------
    nilearn.image.index_img

    """
    ...

def new_img_like(ref_niimg, data, affine=..., copy_header=...): # -> Nifti1Image | FileBasedImage:
    """Create a new image of the same class as the reference image.

    Parameters
    ----------
    ref_niimg : Niimg-like object
        Reference image. The new image will be of the same type.

    data : :class:`numpy.ndarray`
        Data to be stored in the image. If data dtype is a boolean, then data
        is cast to 'uint8' by default.

    .. versionchanged:: 0.9.2
        Changed default dtype casting of booleans from 'int8' to 'uint8'.

    affine : 4x4 :class:`numpy.ndarray`, optional
        Transformation matrix.

    copy_header : :obj:`bool`, optional
        Indicated if the header of the reference image should be used to
        create the new image. Default=False.

    Returns
    -------
    Niimg-like object
        A loaded image with the same file type (and, optionally, header)
        as the reference image.

    """
    ...

def threshold_img(img, threshold, cluster_threshold=..., two_sided=..., mask_img=..., copy=...): # -> Nifti1Image | FileBasedImage:
    """Threshold the given input image, mostly statistical or atlas images.

    Thresholding can be done based on direct image intensities or selection
    threshold with given percentile.

    .. versionchanged:: 0.9.0
        New ``cluster_threshold`` and ``two_sided`` parameters added.

    .. versionadded:: 0.2

    Parameters
    ----------
    img : a 3D/4D Niimg-like object
        Image containing statistical or atlas maps which should be thresholded.

    threshold : :obj:`float` or :obj:`str`
        Voxels with intensities less than the requested threshold
        will be set to zero.
        Those with intensities greater or equal than the requested threshold
        will keep their original value.
        If float, we threshold the image based on image intensities.
        The given value should be within the range of minimum and maximum
        intensity of the input image.
        If string, it should finish with percent sign e.g. "80%"
        and we threshold based on the score obtained
        using this percentile on the image data.
        The given string should be within the range of "0%" to "100%".
        The percentile rank is computed using
        :func:`scipy.stats.scoreatpercentile`.

    cluster_threshold : :obj:`float`, optional
        Cluster size threshold, in voxels. In the returned thresholded map,
        sets of connected voxels (``clusters``) with size smaller
        than this number will be removed. Default=0.

        .. versionadded:: 0.9.0

    two_sided : :obj:`bool`, optional
        Whether the thresholding should yield both positive and negative
        part of the maps.
        Default=True.

        .. versionadded:: 0.9.0

    mask_img : Niimg-like object, default None, optional
        Mask image applied to mask the input data.
        If None, no masking will be applied.

    copy : :obj:`bool`, optional
        If True, input array is not modified. True by default: the filtering
        is not performed in-place. Default=True.

    Returns
    -------
    :class:`~nibabel.nifti1.Nifti1Image`
        Thresholded image of the given input image.

    See Also
    --------
    nilearn.glm.threshold_stats_img :
        Threshold a statistical image using the alpha value, optionally with
        false positive control.

    """
    ...

def math_img(formula, **imgs): # -> Nifti1Image | FileBasedImage:
    """Interpret a numpy based string formula using niimg in named parameters.

    .. versionadded:: 0.2.3

    Parameters
    ----------
    formula : :obj:`str`
        The mathematical formula to apply to image internal data. It can use
        numpy imported as 'np'.

    imgs : images (:class:`~nibabel.nifti1.Nifti1Image` or file names)
        Keyword arguments corresponding to the variables in the formula as
        Nifti images. All input images should have the same geometry (shape,
        affine).

    Returns
    -------
    :class:`~nibabel.nifti1.Nifti1Image`
        Result of the formula as a Nifti image. Note that the dimension of the
        result image can be smaller than the input image. The affine is the
        same as the input image.

    See Also
    --------
    nilearn.image.mean_img : To simply compute the mean of multiple images

    Examples
    --------
    Let's load an image using nilearn datasets module::

     >>> from nilearn import datasets
     >>> anatomical_image = datasets.load_mni152_template()

    Now we can use any numpy function on this image::

     >>> from nilearn.image import math_img
     >>> log_img = math_img("np.log(img)", img=anatomical_image)

    We can also apply mathematical operations on several images::

     >>> result_img = math_img("img1 + img2",
     ...                       img1=anatomical_image, img2=log_img)

    Notes
    -----
    This function is the Python equivalent of ImCal in SPM or fslmaths
    in FSL.

    """
    ...

def binarize_img(img, threshold=..., mask_img=...): # -> Nifti1Image | FileBasedImage:
    """Binarize an image such that its values are either 0 or 1.

    .. versionadded:: 0.8.1

    Parameters
    ----------
    img : a 3D/4D Niimg-like object
        Image which should be binarized.

    threshold : :obj:`float` or :obj:`str`
        If float, we threshold the image based on image intensities meaning
        voxels which have intensities greater than this value will be kept.
        The given value should be within the range of minimum and
        maximum intensity of the input image.
        If string, it should finish with percent sign e.g. "80%" and we
        threshold based on the score obtained using this percentile on
        the image data. The voxels which have intensities greater than
        this score will be kept. The given string should be
        within the range of "0%" to "100%".

    mask_img : Niimg-like object, default None, optional
        Mask image applied to mask the input data.
        If None, no masking will be applied.

    Returns
    -------
    :class:`~nibabel.nifti1.Nifti1Image`
        Binarized version of the given input image. Output dtype is int.

    See Also
    --------
    nilearn.image.threshold_img : To simply threshold but not binarize images.

    Examples
    --------
    Let's load an image using nilearn datasets module::

     >>> from nilearn import datasets
     >>> anatomical_image = datasets.load_mni152_template()

    Now we binarize it, generating a pseudo brainmask::

     >>> from nilearn.image import binarize_img
     >>> img = binarize_img(anatomical_image)

    """
    ...

@rename_parameters({ "sessions": "runs" }, "0.10.0")
def clean_img(imgs, runs=..., detrend=..., standardize=..., confounds=..., low_pass=..., high_pass=..., t_r=..., ensure_finite=..., mask_img=..., **kwargs): # -> list[Unknown] | Nifti1Image | FileBasedImage:
    """Improve SNR on masked fMRI signals.

    This function can do several things on the input signals, in
    the following order:

    - detrend
    - low- and high-pass filter
    - remove confounds
    - standardize

    Low-pass filtering improves specificity.

    High-pass filtering should be kept small, to keep some sensitivity.

    Filtering is only meaningful on evenly-sampled signals.

    According to Lindquist et al. (2018), removal of confounds will be done
    orthogonally to temporal filters (low- and/or high-pass filters), if both
    are specified.

    .. versionadded:: 0.2.5

    Parameters
    ----------
    imgs : Niimg-like object
        4D image. The signals in the last dimension are filtered (see
        :ref:`extracting_data` for a detailed description of the valid input
        types).

    runs : :class:`numpy.ndarray`, optional
        Add a run level to the cleaning process. Each run will be
        cleaned independently. Must be a 1D array of n_samples elements.

        .. warning::

            'runs' replaces 'sessions' after release 0.10.0.
            Using 'session' will result in an error after release 0.10.0.

        Default=``None``.

    detrend : :obj:`bool`, optional
        If detrending should be applied on timeseries
        (before confound removal).
        Default=True.

    standardize : :obj:`bool`, optional
        If True, returned signals are set to unit variance. Default=True.

    confounds : :class:`numpy.ndarray`, :obj:`str` or :obj:`list` of
        Confounds timeseries. optional
        Shape must be (instant number, confound number),
        or just (instant number,)
        The number of time instants in signals and confounds must be
        identical (i.e. signals.shape[0] == confounds.shape[0]).
        If a string is provided, it is assumed to be the name of a csv file
        containing signals as columns, with an optional one-line header.
        If a list is provided, all confounds are removed from the input
        signal, as if all were in the same array.

    low_pass : :obj:`float`, optional
        Low cutoff frequencies, in Hertz.

    high_pass : :obj:`float`, optional
        High cutoff frequencies, in Hertz.

    t_r : :obj:`float`, optional
        Repetition time, in second (sampling period). Set to None if not
        specified. Mandatory if used together with `low_pass` or `high_pass`.

    ensure_finite : :obj:`bool`, optional
        If True, the non-finite values (NaNs and infs) found in the images
        will be replaced by zeros. Default=False.

    mask_img : Niimg-like object, optional
        If provided, signal is only cleaned from voxels inside the mask. If
        mask is provided, it should have same shape and affine as imgs.
        If not provided, all voxels are used.
        See :ref:`extracting_data`.

    kwargs : dict
        Keyword arguments to be passed to functions called
        within this function.
        Kwargs prefixed with ``'clean__'`` will be passed to
        :func:`~nilearn.signal.clean`.
        Within :func:`~nilearn.signal.clean`, kwargs prefixed with
        ``'butterworth__'`` will be passed to the Butterworth filter
        (i.e., ``clean__butterworth__``).

    Returns
    -------
    Niimg-like object
        Input images, cleaned. Same shape as `imgs`.

    Notes
    -----
    Confounds removal is based on a projection on the orthogonal
    of the signal space [:footcite:`Friston1994`].

    Orthogonalization between temporal filters and confound removal is based on
    suggestions in [:footcite:`Lindquist2018`].

    References
    ----------
    .. footbibliography::

    See Also
    --------
        nilearn.signal.clean

    """
    ...

def load_img(img, wildcards=..., dtype=...): # -> Nifti1Image | FileBasedImage | Generator[Nifti1Image | FileBasedImage | Unknown, None, None]:
    """Load a Niimg-like object from filenames or list of filenames.

    .. versionadded:: 0.2.5

    Parameters
    ----------
    img : Niimg-like object
        If string, consider it as a path to NIfTI image and
        call `nibabel.load()`on it.
        The '~' symbol is expanded to the user home folder.
        If it is an object, check if affine attribute is present, raise
        `TypeError` otherwise.
        See :ref:`extracting_data`.

    wildcards : :obj:`bool`, optional
        Use `img` as a regular expression to get a list of matching input
        filenames.
        If multiple files match, the returned list is sorted using an ascending
        order.
        If no file matches the regular expression, a `ValueError` exception is
        raised.
        Default=True.

    dtype : {dtype, "auto"}, optional
        Data type toward which the data should be converted. If "auto", the
        data will be converted to int32 if dtype is discrete and float32 if it
        is continuous.

    Returns
    -------
    3D/4D Niimg-like object
        Result can be :class:`~nibabel.nifti1.Nifti1Image` or the input, as-is.
        It is guaranteed that
        the returned object has an affine attributes and that
        nilearn.image.get_data returns its data.

    """
    ...

def largest_connected_component_img(imgs): # -> list[Unknown]:
    """Return the largest connected component of an image or list of images.

    .. versionadded:: 0.3.1

    Parameters
    ----------
    imgs : Niimg-like object or iterable of Niimg-like objects (3D)
        Image(s) to extract the largest connected component from.
        See :ref:`extracting_data`.

    Returns
    -------
    3D Niimg-like object or list of
        Image or list of images containing the largest connected component.

    Notes
    -----
    **Handling big-endian in given Nifti image**
    This function changes the existing byte-ordering information to new byte
    order, if the dtype in given Nifti image has non-native data type.
    This operation is done internally to avoid big-endian issues with
    scipy ndimage module.

    """
    ...

